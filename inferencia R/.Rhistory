summary(data$mileage)
# Hipotesis para la muestra usando t-student
t.test(data$mileage, mu=16000,  alternative = "greater")
# Valor critico de t
qt (p = 0.95, df = 380, lower.tail = TRUE)
print("Se rechaza H_0 debido a que el valor p < α. Lo que quiere decir que el Kilometraje de la población es mayor a 16000 millas")
print("Prueba de coeficiente correlación entre el Kilometraje y el precio de los autos")
print("H_0: \rho = 0")
print("H_1: \rho \neq 0")
plot(data$mileage,data$price, col = "blue" ,xlab = "Kilometraje", ylab = "Precio")
# Realizar la prueba de correlación
correlation_test <- cor.test(data$mileage, data$price)
# Imprimir los resultados de la prueba
print(correlation_test)
print("Se rechaza H_0, lo que significa que hay una correlación entre kilometraje y el precio de los automoviles usados, esta correlación corresponde a una correlación debil e inversa ya que r=-0.30")
# Hipótesis nula y alternativa
print("H_0: \beta_1 = 0")
print("H_1: \beta_1 \neq 0")
options(scipen = 999)
# Crear un modelo de regresión lineal
modelo <- lm(price ~ mileage, data = data)
# Imprimir un resumen del modelo
summary(modelo)
intercepto <- coef(modelo)[1]
pendiente <- coef(modelo)[2]
# Determinar el signo del coeficiente de la pendiente
signo <- ifelse(pendiente >= 0, "+", "-")
# Imprimir la ecuación de la recta
pendiente <- paste("ŷ=", round(intercepto, 2), signo, abs(round(pendiente, 2)),"x")
print("Se rechaza H_0 debido a que el valor p < α, por lo que β₀ es significativo en el modelo")
print("Ecuación lineal del modelo: ")
cat("ŷ = β₀ + β₁ * x\n")
print(pendiente)
# Graficar los datos
plot(data$mileage, data$price, main = pendiente, xlab = "Kilometraje", ylab = "Precio", pch = 1, col = "blue")
# Agregar la línea de regresión al gráfico
abline(modelo, col = "red")
print("H_0: Los residuos presentan una distribución normal")
print("H_1: Los residuos no presentan una distribución normal")
residuos <- resid(modelo)
# Prueba de normalidad de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos)
# Imprimir el resultado de la prueba
print(shapiro_test)
print("Se rechaza H_0, debido a que el valor p < α. Por ello, los residuos no se distribuyen de manera normal")
print("H_0: La varianza de los errores es constante (homocedasticidad)")
print("H_1: La varianza de los errores no es constante (heterocedasticidad)")
residuos <- resid(modelo)
# Prueba de Breusch-Pagan
breusch_pagan_test <- lmtest::bptest(modelo)
# Imprimir el resultado de la prueba
print(breusch_pagan_test)
print("Se rechaza H0, debido a que el valor p < α. Por ello, los residuos presentan heterocedasticidad, es decir, no presentan varianzas constantes")
print("H_0: pi =< 0.5")
print("H_1: pi > 0.5")
# Contando los autos que usen como combustible Petrol
x <- sum(data$fuelType == "Petrol")
n <- length(data)
z_values <- seq(-3, 3, by = 0.01)
densidad_z <- dnorm(z_values)
valor_z <- ((x/n) - 0.5) / sqrt((0.5 * (1 - 0.5)) / n)
valor_z_critico <- qnorm(0.95)
# Crear el gráfico de densidad de la distribución normal
ggplot(data = data.frame(z = z_values, densidad = densidad_z), aes(x = z, y = densidad)) +
geom_line() +
theme_minimal() +
labs(x = "Valor z", y = "Densidad") +
ggtitle("Distribución Normal Estándar") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z >= valor_z_critico), aes(x = z, y = densidad), fill = "red") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z < valor_z_critico ), aes(x = z, y = densidad), fill = "blue") +
annotate("text", x = valor_z_critico + 1, y = 0.2, label = paste("α =", round(valor_z_critico, 2)), color = "red", size = 4) +
annotate("text", x = valor_z + 1, y = 0.2, label = paste("Z =", round(valor_z, 2)), color = "green", size = 4) +
geom_vline(xintercept = valor_z_critico, color = "red", linetype = "dashed") +
geom_vline(xintercept = valor_z, color = "green", linetype = "dashed")
valorp <- prop.test(x, n, p=0.5, alternative= "greater", conf.level=0.95, correct=FALSE)
print("H_0: pi =< 0.5")
print("H_1: pi > 0.5")
# Contando los autos que usen como combustible Petrol
x <- sum(data$fuelType == "Petrol")
n <- sum(data)
print("H_0: pi =< 0.5")
print("H_1: pi > 0.5")
# Contando los autos que usen como combustible Petrol
x <- sum(data$fuelType == "Petrol")
n <- sum(data$engineSize>=0)
z_values <- seq(-3, 3, by = 0.01)
densidad_z <- dnorm(z_values)
valor_z <- ((x/n) - 0.5) / sqrt((0.5 * (1 - 0.5)) / n)
valor_z_critico <- qnorm(0.95)
# Crear el gráfico de densidad de la distribución normal
ggplot(data = data.frame(z = z_values, densidad = densidad_z), aes(x = z, y = densidad)) +
geom_line() +
theme_minimal() +
labs(x = "Valor z", y = "Densidad") +
ggtitle("Distribución Normal Estándar") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z >= valor_z_critico), aes(x = z, y = densidad), fill = "red") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z < valor_z_critico ), aes(x = z, y = densidad), fill = "blue") +
annotate("text", x = valor_z_critico + 1, y = 0.2, label = paste("α =", round(valor_z_critico, 2)), color = "red", size = 4) +
annotate("text", x = valor_z + 1, y = 0.2, label = paste("Z =", round(valor_z, 2)), color = "green", size = 4) +
geom_vline(xintercept = valor_z_critico, color = "red", linetype = "dashed") +
geom_vline(xintercept = valor_z, color = "green", linetype = "dashed")
valorp <- prop.test(x, n, p=0.5, alternative= "greater", conf.level=0.95, correct=FALSE)
#VALOR P
valorp$p.value
valorp$p.value>0.05
print("Se rechaza H_0 debido a que el valor p < α. Por lo que se obtiene que la mayoria de autos usan gasolina como fuente de combustible")
print("Prueba de ANOVA entre las medias poblacionales de los precios de los autos agrupados por marca")
"H_0: μ_1 = μ_2 = μ_3 = μ_4 = μ_5 = μ_6 = μ_7"
"H_1: Al menos dos de las medias poblacionales de los precios de los autos agrupados por marca son diferentes"
# Convertir 'Make' a factor
data$Make <- as.factor(data$Make)
# Boxplot
boxplot(price ~ Make, data = data, main = "Boxplot de Precio por Marca", xlab = "Marca", ylab = "Precio")
# Promedio por marca
mean_by_make <- tapply(data$price, data$Make, mean)
print("Promedio de precio por marca:")
print(mean_by_make)
# ANOVA
modelo_anova <- aov(lm(price ~ Make, data = data))
summary(modelo_anova)
# Test de Tukey
tukey_results <- TukeyHSD(modelo_anova)
# Imprimir los resultados del Test de Tukey
cat("Resultados del Test de Tukey:\n")
print(tukey_results)
print("Las medias iguales son: BMW-audi, Hyundai-Ford, toyota-Ford, skoda-Hyundai, toyota-Hyundai, toyota-skoda, ")
print("Prueba de ANOVA entre las medias poblacionales de los precios de los autos agrupados por marca")
"H_0: μ_1 = μ_2 = μ_3 = μ_4 = μ_5 = μ_6 = μ_7"
"H_1: Al menos dos de las medias poblacionales de los precios de los autos agrupados por marca son diferentes"
# Convertir 'Make' a factor
data$Make <- as.factor(data$Make)
# Boxplot
boxplot(price ~ Make, data = data, main = "Boxplot de Precio por Marca", xlab = "Marca", ylab = "Precio")
# Promedio por marca
mean_by_make <- tapply(data$price, data$Make, mean)
print("Promedio de precio por marca:")
print(mean_by_make)
# ANOVA
modelo_anova <- aov(lm(price ~ Make, data = data))
print(summary(modelo_anova))
# Test de Tukey
tukey_results <- TukeyHSD(modelo_anova)
# Imprimir los resultados del Test de Tukey
print("Resultados del Test de Tukey:\n")
print(tukey_results)
print("Las medias iguales son: BMW-audi, skoda-Ford, Hyundai-Ford, toyota-Ford, skoda-Hyundai, toyota-Hyundai, toyota-skoda, ")
print("H_0: pi =< 0.5")
print("H_1: pi > 0.5")
# Contando los autos que usen como combustible Petrol
x <- sum(data$fuelType == "Petrol")
n <- sum(data$engineSize>=0)
z_values <- seq(-3, 3, by = 0.01)
densidad_z <- dnorm(z_values)
valor_z <- ((x/n) - 0.5) / sqrt((0.5 * (1 - 0.5)) / n)
valor_z_critico <- qnorm(0.95)
# Crear el gráfico de densidad de la distribución normal
ggplot(data = data.frame(z = z_values, densidad = densidad_z), aes(x = z, y = densidad)) +
geom_line() +
theme_minimal() +
labs(x = "Valor z", y = "Densidad") +
ggtitle("Distribución Normal Estándar") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z >= valor_z_critico), aes(x = z, y = densidad), fill = "red") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z < valor_z_critico ), aes(x = z, y = densidad), fill = "blue") +
annotate("text", x = valor_z_critico + 1, y = 0.2, label = paste("α =", round(valor_z_critico, 2)), color = "red", size = 4) +
annotate("text", x = valor_z + 1, y = 0.2, label = paste("Z =", round(valor_z, 2)), color = "green", size = 4) +
geom_vline(xintercept = valor_z_critico, color = "red", linetype = "dashed") +
geom_vline(xintercept = valor_z, color = "green", linetype = "dashed")
valorp <- prop.test(x, n, p=0.5, alternative= "greater", conf.level=0.95, correct=FALSE)
#VALOR P
valorp$p.value
valorp$p.value>0.05
print("Se rechaza H_0 debido a que el valor p < α. Por lo que se obtiene que la mayoria de autos usan gasolina como fuente de combustible")
print("H_0: La varianza de los errores es constante (homocedasticidad)")
print("H_1: La varianza de los errores no es constante (heterocedasticidad)")
residuos <- resid(modelo)
# Prueba de Breusch-Pagan
breusch_pagan_test <- lmtest::bptest(modelo)
# Imprimir el resultado de la prueba
print(breusch_pagan_test)
print("Se rechaza H0, debido a que el valor p < α. Por ello, los residuos presentan heterocedasticidad, es decir, no presentan varianzas constantes")
print("H_0: Los residuos presentan una distribución normal")
print("H_1: Los residuos no presentan una distribución normal")
residuos <- resid(modelo)
# Prueba de normalidad de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos)
# Imprimir el resultado de la prueba
print(shapiro_test)
print("Se rechaza H_0, debido a que el valor p < α. Por ello, los residuos no se distribuyen de manera normal")
# Hipótesis nula y alternativa
print("H_0: \beta_1 = 0")
print("H_1: \beta_1 \neq 0")
options(scipen = 999)
# Crear un modelo de regresión lineal
modelo <- lm(price ~ mileage, data = data)
# Imprimir un resumen del modelo
summary(modelo)
intercepto <- coef(modelo)[1]
pendiente <- coef(modelo)[2]
# Determinar el signo del coeficiente de la pendiente
signo <- ifelse(pendiente >= 0, "+", "-")
# Imprimir la ecuación de la recta
pendiente <- paste("ŷ=", round(intercepto, 2), signo, abs(round(pendiente, 2)),"x")
print("Se rechaza H_0 debido a que el valor p < α, por lo que β₀ es significativo en el modelo")
print("Ecuación lineal del modelo: ")
cat("ŷ = β₀ + β₁ * x\n")
print(pendiente)
# Graficar los datos
plot(data$mileage, data$price, main = pendiente, xlab = "Kilometraje", ylab = "Precio", pch = 1, col = "blue")
# Agregar la línea de regresión al gráfico
abline(modelo, col = "red")
print("Prueba de coeficiente correlación entre el Kilometraje y el precio de los autos")
print("H_0: \rho = 0")
print("H_1: \rho \neq 0")
plot(data$mileage,data$price, col = "blue" ,xlab = "Kilometraje", ylab = "Precio")
# Realizar la prueba de correlación
correlation_test <- cor.test(data$mileage, data$price)
# Imprimir los resultados de la prueba
print(correlation_test)
print("Se rechaza H_0, lo que significa que hay una correlación entre kilometraje y el precio de los automoviles usados, esta correlación corresponde a una correlación debil e inversa ya que r=-0.28")
print("Prueba de ANOVA entre las medias poblacionales de los precios de los autos agrupados por marca")
"H_0: μ_1 = μ_2 = μ_3 = μ_4 = μ_5 = μ_6 = μ_7"
"H_1: Al menos dos de las medias poblacionales de los precios de los autos agrupados por marca son diferentes"
# Convertir 'Make' a factor
data$Make <- as.factor(data$Make)
# Boxplot
boxplot(price ~ Make, data = data, main = "Boxplot de Precio por Marca", xlab = "Marca", ylab = "Precio")
# Promedio por marca
mean_by_make <- tapply(data$price, data$Make, mean)
print("Promedio de precio por marca:")
print(mean_by_make)
# ANOVA
modelo_anova <- aov(lm(price ~ Make, data = data))
print(summary(modelo_anova))
print("Se rechaza H_0 debido a que el valor p < α. Lo que significa que hay al menos dos medias diferentes.")
print("Por eso se hace un POST ANOVA con el test de Tukey para conocer las medias iguales y diferentes")
# Test de Tukey
tukey_results <- TukeyHSD(modelo_anova)
# Imprimir los resultados del Test de Tukey
print("Resultados del Test de Tukey:\n")
print(tukey_results)
print("Las medias iguales son: BMW-audi, skoda-Ford, Hyundai-Ford, toyota-Ford, skoda-Hyundai, toyota-Hyundai, toyota-skoda")
print("H_0: pi =< 0.5")
print("H_1: pi > 0.5")
# Contando los autos que usen como combustible Petrol
x <- sum(data$fuelType == "Petrol")
n <- sum(data$engineSize>=0)
z_values <- seq(-3, 3, by = 0.01)
densidad_z <- dnorm(z_values)
valor_z <- ((x/n) - 0.5) / sqrt((0.5 * (1 - 0.5)) / n)
valor_z_critico <- qnorm(0.95)
# Crear el gráfico de densidad de la distribución normal
ggplot(data = data.frame(z = z_values, densidad = densidad_z), aes(x = z, y = densidad)) +
geom_line() +
theme_minimal() +
labs(x = "Valor z", y = "Densidad") +
ggtitle("Distribución Normal Estándar") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z >= valor_z_critico), aes(x = z, y = densidad), fill = "red") +
geom_area(data = subset(data.frame(z = z_values, densidad = densidad_z), z < valor_z_critico ), aes(x = z, y = densidad), fill = "blue") +
annotate("text", x = valor_z_critico + 1, y = 0.2, label = paste("α =", round(valor_z_critico, 2)), color = "red", size = 4) +
annotate("text", x = valor_z + 1, y = 0.2, label = paste("Z =", round(valor_z, 2)), color = "green", size = 4) +
geom_vline(xintercept = valor_z_critico, color = "red", linetype = "dashed") +
geom_vline(xintercept = valor_z, color = "green", linetype = "dashed")
valorp <- prop.test(x, n, p=0.5, alternative= "greater", conf.level=0.95, correct=FALSE)
#VALOR P
valorp$p.value
valorp$p.value>0.05
print("Se rechaza H_0 debido a que el valor p < α. Por lo que se obtiene que la mayoria de autos usan gasolina como fuente de combustible")
print("H_0: μ =< 16000")
print("H_1: μ > 1600")
summary(data$mileage)
# Hipotesis para la muestra usando t-student
t.test(data$mileage, mu=16000,  alternative = "greater")
# Valor critico de t
qt (p = 0.95, df = 380, lower.tail = TRUE)
print("No se rechaza H_0 debido a que el valor p > α. No hay suficiente evidencia estadistica para decir que el Kilometraje de la población es mayor a 16000 millas")
nFord <- sum(data$Make == "Ford")
result <- prop.test(nFord, n, p=0.5, alternative= "two.sided", conf.level=0.95, correct=FALSE)
print(result)
print("El intervalo de proporción de autos Ford está entre 0.2286801 y 0.2637388")
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
library(readr)
library(tidyverse)
library(dplyr)
library(xts)
library(psych)
library(gmodels)
library(MASS)
library(fitdistrplus)
library(lmtest)
library(fdth)
library(ggplot2)
library(plotly)
library(PASWR2)
library(lattice)
library(descr)
library(openxlsx)
library(kableExtra)
library(pastecs)
library(multcomp)
#Asignar directorio de trabajo
setwd('C:/Universidad/Universidad/Inferencia Estadistica/inferencia-estadistica-R/inferencia R')
#Comprobar directorio de trabajo
getwd()
datos <-  read_csv("cars_dataset.csv", show_col_types = FALSE)
#view(datos)
attach(datos)
data  <- datos %>%
filter(year >= 2018 & year <= 2020 & mileage>5000)
attach(data)
print("Prueba de coeficiente correlación entre el Kilometraje y el precio de los autos")
print("H_0: \rho = 0")
print("H_1: \rho \neq 0")
plot(data$mileage,data$price, col = "blue" ,xlab = "Kilometraje", ylab = "Precio")
# Realizar la prueba de correlación
correlation_test <- cor.test(data$mileage, data$price)
# Imprimir los resultados de la prueba
print(correlation_test)
print("Se rechaza H_0, lo que significa que hay una correlación entre kilometraje y el precio de los automoviles usados, esta correlación corresponde a una correlación debil e inversa ya que r=-0.28")
# Hipótesis nula y alternativa
print("H_0: \beta_1 = 0")
print("H_1: \beta_1 \neq 0")
options(scipen = 999)
# Crear un modelo de regresión lineal
modelo <- lm(price ~ mileage, data = data)
# Imprimir un resumen del modelo
summary(modelo)
intercepto <- coef(modelo)[1]
pendiente <- coef(modelo)[2]
# Determinar el signo del coeficiente de la pendiente
signo <- ifelse(pendiente >= 0, "+", "-")
# Imprimir la ecuación de la recta
pendiente <- paste("ŷ=", round(intercepto, 2), signo, abs(round(pendiente, 2)),"x")
print("Se rechaza H_0 debido a que el valor p < α, por lo que β₀ es significativo en el modelo")
print("Ecuación lineal del modelo: ")
cat("ŷ = β₀ + β₁ * x\n")
print(pendiente)
# Graficar los datos
plot(data$mileage, data$price, main = pendiente, xlab = "Kilometraje", ylab = "Precio", pch = 1, col = "blue")
# Agregar la línea de regresión al gráfico
abline(modelo, col = "red")
print("H_0: Los residuos presentan una distribución normal")
print("H_1: Los residuos no presentan una distribución normal")
residuos <- resid(modelo)
# Prueba de normalidad de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos)
# Imprimir el resultado de la prueba
print(shapiro_test)
print("Se rechaza H_0, debido a que el valor p < α. Por ello, los residuos no se distribuyen de manera normal")
print("H_0: La varianza de los errores es constante (homocedasticidad)")
print("H_1: La varianza de los errores no es constante (heterocedasticidad)")
residuos <- resid(modelo)
# Prueba de Breusch-Pagan
breusch_pagan_test <- lmtest::bptest(modelo)
# Imprimir el resultado de la prueba
print(breusch_pagan_test)
print("Se rechaza H0, debido a que el valor p < α. Por ello, los residuos presentan heterocedasticidad, es decir, no presentan varianzas constantes")
# Supongamos que 'modelo_regresion' es tu modelo de regresión ajustado
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo)
# Intervalo de predicción para la regresión (95% por defecto)
intervalo_prediccion_regresion <- predict(modelo, interval = "prediction")
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Intervalo de Predicción para la Regresión:")
print(intervalo_prediccion_regresion)
# Intervalo de predicción para la regresión (95% por defecto)
intervalo_prediccion_regresion <- predict(modelo, interval = "prediction")
print("Intervalo de Predicción para la Regresión:")
print(intervalo_prediccion_regresion)
# Supongamos que 'modelo_regresion' es tu modelo de regresión ajustado
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo)
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Prueba de coeficiente correlación entre el Kilometraje y el precio de los autos")
print("H_0: \rho = 0")
print("H_1: \rho \neq 0")
plot(data$mileage,data$price, col = "blue" ,xlab = "Kilometraje", ylab = "Precio")
# Realizar la prueba de correlación
correlation_test <- cor.test(data$mileage, data$price)
# Imprimir los resultados de la prueba
print(correlation_test)
print("Se rechaza H_0, lo que significa que hay una correlación entre kilometraje y el precio de los automoviles usados, esta correlación corresponde a una correlación debil e inversa ya que r=-0.28")
# Hipótesis nula y alternativa
print("H_0: \beta_1 = 0")
print("H_1: \beta_1 \neq 0")
options(scipen = 999)
# Crear un modelo de regresión lineal
modelo <- lm(price ~ mileage, data = data)
# Imprimir un resumen del modelo
summary(modelo)
intercepto <- coef(modelo)[1]
pendiente <- coef(modelo)[2]
# Determinar el signo del coeficiente de la pendiente
signo <- ifelse(pendiente >= 0, "+", "-")
# Imprimir la ecuación de la recta
pendiente <- paste("ŷ=", round(intercepto, 2), signo, abs(round(pendiente, 2)),"x")
print("Se rechaza H_0 debido a que el valor p < α, por lo que β₀ es significativo en el modelo")
print("Ecuación lineal del modelo: ")
cat("ŷ = β₀ + β₁ * x\n")
print(pendiente)
# Graficar los datos
plot(data$mileage, data$price, main = pendiente, xlab = "Kilometraje", ylab = "Precio", pch = 1, col = "blue")
# Agregar la línea de regresión al gráfico
abline(modelo, col = "red")
# Intervalo de predicción para la regresión (95% por defecto)
intervalo_prediccion_regresion <- predict(modelo, interval = "prediction", level = 0.95)
print("Intervalo de Predicción para la Regresión:")
print(intervalo_prediccion_regresion)
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo, level = 0.95)
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Intercepto:
Con un 95% de confianza, el valor real del intercepto (el precio cuando el kilometraje es cero) se espera que esté entre $23,661.37 y $25,673.50.
Kilometraje:
Con un 95% de confianza, se espera que por cada unidad adicional de kilometraje, el precio disminuya entre $0.3374 y $0.4819.")
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo, level = 0.95)
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Intercepto:
Con un 95% de confianza, el valor real del intercepto (el precio cuando el kilometraje es cero) se espera que esté entre $23,661.37 y $25,673.50.
Kilometraje:
Con un 95% de confianza, se espera que por cada unidad adicional de kilometraje, el precio disminuya entre $0.3374 y $0.4819.")
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo, level = 0.95)
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Intercepto:
Con un 95% de confianza, el valor real del intercepto (el precio cuando el kilometraje es cero) se espera que esté entre $23,661.37 y $25,673.50.
Kilometraje:Con un 95% de confianza, se espera que por cada unidad adicional de kilometraje, el precio disminuya entre $0.3374 y $0.4819.")
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo, level = 0.95)
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Intercepto:Con un 95% de confianza, el valor real del intercepto (el precio cuando el kilometraje es cero) se espera que esté entre $23,661.37 y $25,673.50.
Kilometraje:Con un 95% de confianza, se espera que por cada unidad adicional de kilometraje, el precio disminuya entre $0.3374 y $0.4819.")
predicciones <- predict(modelo, newdata = datos_prueba, interval = "prediction", level = 0.95)
predicciones <- predict(modelo, newdata = data, interval = "prediction", level = 0.95)
# Extrae los límites inferior y superior de los intervalos de predicción
limite_inferior <- predicciones[, "lwr"]
limite_superior <- predicciones[, "upr"]
# Visualiza los resultados
resultados <- data.frame(Prediccion = predicciones[, 1], LimiteInferior = limite_inferior, LimiteSuperior = limite_superior)
print(resultados)
# Hipótesis nula y alternativa
print("H_0: \beta_1 = 0")
print("H_1: \beta_1 \neq 0")
options(scipen = 999)
# Crear un modelo de regresión lineal
modelo <- lm(price ~ mileage, data = data)
# Imprimir un resumen del modelo
summary(modelo)
intercepto <- coef(modelo)[1]
pendiente <- coef(modelo)[2]
# Determinar el signo del coeficiente de la pendiente
signo <- ifelse(pendiente >= 0, "+", "-")
# Imprimir la ecuación de la recta
pendiente <- paste("ŷ=", round(intercepto, 2), signo, abs(round(pendiente, 2)),"x")
print("Se rechaza H_0 debido a que el valor p < α, por lo que β₀ es significativo en el modelo")
print("Ecuación lineal del modelo: ")
cat("ŷ = β₀ + β₁ * x\n")
print(pendiente)
# Graficar los datos
plot(data$mileage, data$price, main = pendiente, xlab = "Kilometraje", ylab = "Precio", pch = 1, col = "blue")
# Agregar la línea de regresión al gráfico
abline(modelo, col = "red")
print("H_0: Los residuos presentan una distribución normal")
print("H_1: Los residuos no presentan una distribución normal")
residuos <- resid(modelo)
# Prueba de normalidad de Shapiro-Wilk
shapiro_test <- shapiro.test(residuos)
# Imprimir el resultado de la prueba
print(shapiro_test)
print("Se rechaza H_0, debido a que el valor p < α. Por ello, los residuos no se distribuyen de manera normal")
print("H_0: La varianza de los errores es constante (homocedasticidad)")
print("H_1: La varianza de los errores no es constante (heterocedasticidad)")
residuos <- resid(modelo)
# Prueba de Breusch-Pagan
breusch_pagan_test <- lmtest::bptest(modelo)
# Imprimir el resultado de la prueba
print(breusch_pagan_test)
print("Se rechaza H0, debido a que el valor p < α. Por ello, los residuos presentan heterocedasticidad, es decir, no presentan varianzas constantes")
predicciones <- predict(modelo, newdata = data, interval = "prediction", level = 0.95)
# Extrae los límites inferior y superior de los intervalos de predicción
limite_inferior <- predicciones[, "lwr"]
limite_superior <- predicciones[, "upr"]
# Visualiza los resultados
resultados <- data.frame(Prediccion = predicciones[, 1], LimiteInferior = limite_inferior, LimiteSuperior = limite_superior)
print(resultados)
# Realiza las predicciones con intervalos de confianza
predicciones_ci <- predict(modelo, newdata = data, interval = "confidence", level = 0.95)
# Extrae los límites inferior y superior de los intervalos de confianza
limite_inferior_ci <- predicciones_ci[, "lwr"]
limite_superior_ci <- predicciones_ci[, "upr"]
# Visualiza los resultados
resultados_ci <- data.frame(Prediccion = predicciones_ci[, 1], LimiteInferior = limite_inferior_ci, LimiteSuperior = limite_superior_ci)
print(resultados_ci)
# Intervalo de confianza para la regresión (95% por defecto)
intervalo_confianza_regresion <- confint(modelo, level = 0.95)
# Imprimir los resultados
print("Intervalo de Confianza para la Regresión:")
print(intervalo_confianza_regresion)
print("Intercepto:Con un 95% de confianza, el valor real del intercepto (el precio cuando el kilometraje es cero) se espera que esté entre $23,661.37 y $25,673.50.
Kilometraje:Con un 95% de confianza, se espera que por cada unidad adicional de kilometraje, el precio disminuya entre $0.3374 y $0.4819.")
